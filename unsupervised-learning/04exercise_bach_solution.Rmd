---
title: "Open exercise unsupervised learning using BACH data"
author: "Sebastian Sternberg"
date: "17 November 2017"
output: html_document
---
For the next 1h, we work with the BACH (Bank for the Accounts of Companies Harmonized) data set which you already know from yesterday. We provide you with a smaller version of this data set mainly for computational reasons, but the exercises can be easily extended to the whole data set as well. 


```{r}
library("caret")
library("factoextra")
library("plot3Drgl")
library("plot3D")


rm(list = ls())
load("BACH.Rda")

```



# Multidimensional scaling using the bach data sets

We are interested how similar countries are with respect to the structure of the companies which the bach data set contain. In order to compare countries, we would like to map them on a two-dimensional map. 

In order to achieve this, we first have to aggregate all numeric variables on the country level. In R, this is done as follows:


```{r}

head(bach)

agg_bach_countries <- bach[, 5:ncol(bach)] #subset bach data only including numeric variables

agg_bach_countries$country <- bach$country #assign countries to it

agg_bach_countries <- aggregate(. ~ country, agg_bach_countries, mean) #aggregate on country level

head(agg_bach_countries)


```


## Produce a 2-dimensional map of the bach data using classical MDS

Create a matrix just containing the numeric variables in the data set (i.e., only containing column 2: 11).


```{r}

agg_bach_country_matrix <- as.matrix(agg_bach_countries[, 2:ncol(agg_bach_countries)])

```

Scale this matrix.

```{r}

agg_bach_country_scaled <- scale(agg_bach_country_matrix)


```

Calculate Euclidian distances for this scaled matrix

```{r}


dist.bach.country <- dist(agg_bach_country_scaled)


```

Apply classical MDS to this matrix (cmdscale)

```{r}


mds.bach.country <- cmdscale(dist.bach.country, eig = T, k = 2)


```


Evaluate the goodness of fit. 

```{r}

mds.bach.country$GOF

```


Finally, plot the classical MDS configuration in a 2-dimensional plot.

```{r}


#plot the mds configuration
plot(mds.bach.country$points, xlab="Coordinate 1", ylab="Coordinate 2", 
     main="Metric	MDS for Bach data, \n aggregated by country",type = "n")

text(mds.bach.country$points, labels = agg_bach_countries$country, cex = 0.7) 



```


## Classical MDS for aggregration on sector level

Next, we are interested in how similar companies from different sectors are. In order to do so, we have to aggregate the data on the sector level (ignoring the country structure). 

Modify the code from above to aggregate the data by sector

```{r}


agg_bach_sector <- bach[, 5:ncol(bach)]
agg_bach_sector$sector <- bach$sector

agg_bach_sector <- aggregate(. ~ sector, agg_bach_sector, mean)


```


Follow the steps from before to produce a 2-dimensional map of the similarity of companies for different sectors. 


```{r}


#Use MDS to map the sector into a 2-dimensional map 

agg_bach_sector_matrix <- as.matrix(agg_bach_sector[, 2:ncol(agg_bach_sector)])

agg_bach_sector_scaled <- scale(agg_bach_sector_matrix)

dist.bach.sector <- dist(agg_bach_sector_scaled)

mds.bach.sector <- cmdscale(dist.bach.sector, eig = T, k = 2)

mds.bach.sector$GOF


#plot the mds configuration
plot(mds.bach.sector$points, xlab="Coordinate 1", ylab="Coordinate 2", 
     main="Metric	MDS for Bach data, \n aggregated by sector",type = "n")

text(mds.bach.sector$points, labels = agg_bach_sector$sector, cex = 0.7) 


```


## Use Manhattan metric instead of Euclidian distance. 

Use the Manhatten metric instead of the Euclidian distance for the aggregated by sector data set. Do the results change?

For this, produce two maps (one with Euclidian distances used as input and one with the Manhattan distance). Plot the two graphs side by side. 

```{r}

par(mfrow = c(1,2))


agg_bach_sector_scaled <- scale(agg_bach_sector_matrix)

dist.bach.sector <- dist(agg_bach_sector_scaled)

mds.bach.sector <- cmdscale(dist.bach.sector, eig = T, k = 2)

mds.bach.sector$GOF


#plot the mds configuration
plot(mds.bach.sector$points, xlab="Coordinate 1", ylab="Coordinate 2", 
     main="Metric	MDS for Bach data, \n aggregated by sector",type = "n")

text(mds.bach.sector$points, labels = agg_bach_sector$sector, cex = 0.7) 


#Use the Manhattan distance##################

dist.bach.sector <- dist(agg_bach_sector_scaled, method = "manhattan")

mds.bach.sector <- cmdscale(dist.bach.sector, eig = T, k = 2)
mds.bach.sector$GOF

#plot the mds configuration
plot(mds.bach.sector$points[, 1], -1* mds.bach.sector$points[, 2], xlab="Coordinate 1", ylab="Coordinate 2", 
     main="Metric	MDS for Bach data, \n aggregated by sector",type = "n")

text(mds.bach.sector$points[, 1], -1* mds.bach.sector$points[, 2], labels = agg_bach_sector$sector, cex = 0.7) 
#here, we multiply by minus 1 so that we can flix the axes

par(mfrow = c(1,1))



```


## Excursion: ploting in 3D in R. 

Suppose we want to look at the first three dimensions of an MDS-(or PCA- or Cluster- ) solution (because it explains more of the variance, for instance). 

```{r}

#Excursion: plot 3d
library("plot3Drgl")
library("plot3D")


#rerun sector mds with k = 3

mds.bach.country <- cmdscale(dist.bach.country, eig = T, k = 3)

mds.bach.country$GOF #three dimensional configuration explains 83 of variance


#3-D plot MDS

#Create x,y refs 
data.x <- mds.bach.country$points[,1] 
data.y <- mds.bach.country$points[,2] 
data.z <- mds.bach.country$points[,3] 

# Create a scatter plot
scatter3D(data.x, data.y, data.z, phi = 0, 
          bty = "f", 
          pch = 20, 
          colvar = NULL, 
          ticktype = "detailed")

# Add text
text3D(data.x, data.y, data.z,  agg_bach_countries$country,
       add = TRUE, colkey = FALSE, cex = 1.2)

#We could also create an interactive version of this graph:
plotrgl()



```



# PCA for dimensionality reduction and data inspection

Now we want to apply PCA to the Bach data. 

Use the Bach data set and apply PCA to it (using the prcomp function). Remember to scale the data. 

```{r}

pca.bach <- prcomp(bach[, 5:ncol(bach)], scale. = T)

```

Check the goodness of fit. Produce a scree plot, and decide how many principle components we need. 

```{r}

#Check goodness of fit
#scree plot
summary(pca.bach)

pca.bach.var <- pca.bach$sdev ^ 2
pca.bach.pvar <- pca.bach.var/sum(pca.bach.var)

#This gives us exactly the variance obtained va 

plot(pca.bach.pvar,
     xlab="Principal Components", 
     ylab="Proportion of variance explained", 
     ylim=c(0,1), 
     type='b', 
     xaxt='n', 
     bty = "n", 
     las = 1, 
     cex=1.5,
     cex.axis = 1.5, 
     lwd = 2, 
     cex.lab=1.5)
axis(side = 1, at = 1:nrow(pca.bach$rotation), tck = 0)

```

Create a biplot of the PCA. 

```{r}

#look at the biplot
biplot(pca.bach,
       xlab = "First Principal Component",
       ylab = "Second Principal Component",
       xlabs = rep("*", nrow(bach))) #the labels should not be displayed so that we see more


```

Now we want to use the PCA results to improve the classification tree prediction model of the dummy profit or loss variable from yesterday. We do this in two steps. First, we split the data into training and test set. Second, we run the same model as yesterday using the caret package (and rpart as method). Third, we run the model that only uses the principle components instead of the original variables. Fourth, compare the results of the two models, also including the out-of-sample prediction.

Step 1: Data pre-processing just as yesterday
```{r}

require(caret)

## Data preparation

bach$D_loss <- ifelse(bach$net_profit_or_loss < 0, 1, 0)
bach$D_loss <- as.factor(bach$D_loss)

prop.table(table(bach$D_loss))

set.seed(7345)

bach$year <- as.numeric(as.character(bach$year))
bach_test <- bach[bach$year == 2015,]
bach_train <- bach[bach$year < 2015,]

```

Step 2: Run the original classification tree (rpart) from yesterday. Do not use net_profit_or_loss or return_on_equity in this model.

```{r}

#Run classification tree using the original variables in the data set
set.seed(1234)

folds <- groupKFold(bach_train$year) 

ctrl  <- trainControl(method = "cv",
                      number = 15,
                      index = folds)

#Run the classification tree
rpart.bach.original <- train(D_loss ~ .-return_on_equity -net_profit_or_loss, #we exclude return_on_equity and net_profit
                        method = "rpart",
                        bach_train,
                        trControl = ctrl)


```

Step 3: Run the same model, but only use the principle components as the input data. For this, you need to create a new data set only consisting of the first few principle components and the outcome variables first. You can then run the regression tree on this data.

```{r}
#Rerun rpart with pca as input data

#First, extract the principle components and write them into a new data frame
bach_pcascores <- as.data.frame(pca.bach$x[, 1:9])

#Second, append original outcome variable to this data frame
bach_pcascores$D_loss <- bach$D_loss

#Run the model
set.seed(1234)
rpart.bach.pca <- train(D_loss ~ .,
                        method = "rpart",
                        bach_pcascores,
                        trControl = ctrl)
```

Step 4: Compare the predictive power of the two models. Which one is better?

Insample comparison:
```{r}

#Insample comparison:
rpart.bach.original$results #Accuracy around 87
rpart.bach.pca$results #Accuracy around 89

```


Out-of-sample comparison:
```{r}

#OOS for original model
rf_class <- predict(rpart.bach.original, newdata = bach_test)

#OOS with rpart including PCA
#transform test into PCA
test.data <- predict(pca.bach, newdata = bach_test)
test.data <- as.data.frame(test.data)

#select the first 9 components as we did before
test.data <- test.data[,1:9]
test.data$D_loss <- bach_test$D_loss

#do the prediction
pred.bach.rpart.pca <- predict(rpart.bach.pca, test.data)

#Look at confusion matrix
confusionMatrix(rf_class, bach_test$D_loss)
confusionMatrix(pred.bach.rpart.pca, bach_test$D_loss)

```

For the rpart model, using PCA imroved the prediction a bit. Moreover, if one would do the same for more complex models (such as random forest), we would see a difference at least in the computational time needed for both models (PCA model should be faster). 

# Clustering

Lastly, clustering should be applied to the bach data set. For simplicity, we only use data from 2015. 


```{r}
#subset data set, and delete D-loss variable
bach$D_loss <- NULL
bach_2015 <- bach[bach$year == 2015, ]

```


Create a scaled version of this data set. Remember that k-means only works with numeric data, so you also need to drop the first 4 columns.

```{r}

bach_scaled_2015 <- scale(bach_2015[, 5:ncol(bach_2015) ])

```

Before we start with k-means, we need to decide how many clusters we want to find. We can use the "elbow" method for that. 

```{r}
library(factoextra)

fviz_nbclust(bach_scaled_2015, #data set we want to use
             kmeans, #cluster method
             method = "wss", #"wss" =  total within sum of square
             k.max = 30) +
labs(subtitle = "Elbow method")


```

We start with nine clusters. Use k-means with k = 9. 

```{r}

bach.kmeans9 <- kmeans(bach_scaled_2015, 9 , nstart = 50) 

```

Use the eclust package to visualize the cluster solution. For this, use the eclust function to run k-means with k = 9 again. Plot the output using the fviz_cluster function. 


```{r}

# K-means clustering
km.res <- eclust(bach_scaled_2015, "kmeans", k = 9, nstart = 50, graph = FALSE)

# Visualize k-means clusters
fviz_cluster(km.res, geom = "point", ellipse.type = "norm",
             palette = "jco", ggtheme = theme_minimal())

```


For a further check, create a table that shows the cluster assignment over the sectors and over the countries. 

```{r}

#What did we cluster?

table(bach_2015$country, bach.kmeans9$cluster)
table(bach_2015$size, bach.kmeans9$cluster)


```

If necessary, you can re-run k-means for different numbers of k. 

# Hierarchical clustering

Lastly, we want to apply hierarchical clustering on the bach data set. For h-clust, we need a distance matrix as an input. We create a distance matrix using Euclidean distance for the reduced bach 2015 data set. 

```{r}

dist.bach.de <- dist(bach_scaled_2015, method = "euclidean") # distance matrix

```

Now you can run a hierarchical cluster anaylsis using the hclust function.

```{r}
hclust.bach.de <- hclust(dist.bach.de)

```

Plot the dendogram and draw red borders around 10 clusters

```{r}

# display dendogram
plot(hclust.bach.de,
     xlab="", 
     ylab= "",
     sub="",
     hang = -1) #labels all on the same level

# draw dendogram with red borders around the 10 clusters 
rect.hclust(hclust.bach.de, 
            k=10, 
            border="red")


```

Validate the cluster solution just as for k-means before.

```{r}

hc.res <- eclust(bach_scaled_2015, "hclust", k = 10, 
                 hc_metric = "euclidean", 
                 hc_method = "complete", 
                 graph = FALSE)

fviz_cluster(hc.res, geom = "point", ellipse.type = "norm",
             palette = "jco", ggtheme = theme_minimal())


```


# Use cluster assignment to improve prediction

Finally, we would like to use clustering to improve our model of the prediction of the net income or loss of a company. We stick with the data from 2015.

```{r}

## Data preparation
bach_2015$D_loss <- ifelse(bach_2015$net_profit_or_loss < 0, 1, 0)
bach_2015$D_loss <- as.factor(bach_2015$D_loss)

prop.table(table(bach$D_loss))

#we append the cluster solution to the original data set
bach_2015$kmeans9 <- as.factor(bach.kmeans9$cluster)


#We split the data into training and test, using the whole 2015 data set 
set.seed(7345)

iffer_sampling <- sample(1:nrow(bach_2015), 0.8*nrow(bach_2015))
bach_test_2015 <- bach_2015[-iffer_sampling,]
bach_train_2015 <- bach_2015[iffer_sampling,]

```

Now we can start with the models. Run one model using the 2015 training data set, not using the kmeans9 , net_profit_or_loss or return_on_equity variable. Include the kmeans9 variable in the second run

```{r}

#set up CV:
ctrl  <- trainControl(method = "cv",
                      number = 5)

#First run
set.seed(1234)
rpart_bach_2015 <- train(D_loss ~ .-kmeans9 -net_profit_or_loss -return_on_equity,
                    method = "rpart",
                    bach_train_2015,
                    trControl = ctrl
)

rpart_bach_2015$results

#Second rund
set.seed(1234)
rpart_bach.2015.cluster <- train(D_loss ~ . -net_profit_or_loss -return_on_equity, #here we include the cluster assignment
                    method = "rpart",
                    bach_train_2015,
                    trControl = ctrl
)

                  
rpart_bach.2015.cluster$results

```

We also need to check the out-of-sample performance

```{r}

#Assess OOS performance

#Assess OOS performance

pred.bach.rpart.2015 <- predict(rpart_bach_2015, newdata = bach_test_2015)
pred.bach.rpart.2015.cluster <- predict(rpart_bach.2015.cluster, newdata = bach_test_2015)

confusionMatrix(pred.bach.rpart.2015, bach_test_2015$D_loss)
confusionMatrix(pred.bach.rpart.2015.cluster, bach_test_2015$D_loss)



```

Unfortunately, the cluster information did not help to improve the prediction. We could now continue to search for different cluster solutions, for instance for different numbers of k. 



